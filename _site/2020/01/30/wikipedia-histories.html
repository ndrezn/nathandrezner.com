<!-- 
  _                                              _        _                               _         __       _ 
 | |                                            | |      (_)                             | |       /_/      | |
 | |__   ___  _ __ ___   ___ _ __ ___   __ _  __| | ___   _ _ __    _ __ ___   ___  _ __ | |_ _ __ ___  __ _| |
 | '_ \ / _ \| '_ ` _ \ / _ \ '_ ` _ \ / _` |/ _` |/ _ \ | | '_ \  | '_ ` _ \ / _ \| '_ \| __| '__/ _ \/ _` | |
 | | | | (_) | | | | | |  __/ | | | | | (_| | (_| |  __/ | | | | | | | | | | | (_) | | | | |_| | |  __/ (_| | |
 |_| |_|\___/|_| |_| |_|\___|_| |_| |_|\__,_|\__,_|\___| |_|_| |_| |_| |_| |_|\___/|_| |_|\__|_|  \___|\__,_|_|
                                                                                                               
                                                                                                               
              _   _                             _                                                 
             | | | |                  ____     | |                                                
  _ __   __ _| |_| |__   __ _ _ __   / __ \  __| |_ __ ___ _____ __   ___ _ __ ___ ___  _ __ ___  
 | '_ \ / _` | __| '_ \ / _` | '_ \ / / _` |/ _` | '__/ _ \_  / '_ \ / _ \ '__/ __/ _ \| '_ ` _ \ 
 | | | | (_| | |_| | | | (_| | | | | | (_| | (_| | | |  __// /| | | |  __/ |_| (_| (_) | | | | | |
 |_| |_|\__,_|\__|_| |_|\__,_|_| |_|\ \__,_|\__,_|_|  \___/___|_| |_|\___|_(_)\___\___/|_| |_| |_|
                                     \____/                                           

-->             
                                                                                                  


<!DOCTYPE html>
<html>
  <head>
    <title>Wikipedia Histories</title>
    <meta charset="utf-8"/>

    <link rel = "stylesheet" type = "text/css" href = "/css/main.css" />

    <meta property="og:image" content="https://ndrezn.github.io/images/social-preview.jpg">
    <meta property="og:type" content="website">
    <meta property="og:image:type" content="image/jpg">
    <meta property="og:image:width" content="1680">
    <meta property="og:image:height" content="1050">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-156698951-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-156698951-1');
    </script> 


  </head>


  <body>
  
    <header>
      <div id='location'>
        <a href="/">Nathan Drezner</a>
            <div>Montréal, QC</div>
        </div>

        <div id='nav'>
          <a class='page-link ' href='/research'>Research</a><br>
          <a class='page-link ' href='/photography'>Photography</a><br>
          <a class='page-link ' href='/other'>Other Work</a>

      </div>
    </header>
    <footer>
      <div id='footer'>
            <div id='email'><a href = "mailto:nathan@drezner.com">nathan (at) drezner (dot) com</a><br><br></div>
        </div>
    </footer>

    <div id = 'body-text' class = 'contact'>
	<h2>Wikipedia Histories</h2>
	<h4>January 30, 2020</h4>
	<p>I’ve just released a project onto PyPi, <code class="highlighter-rouge">wikipedia-histories</code>. I built it in fall 2018, and I’m just releasing it now after restructuring it into a generalizable tool.</p>

<p>After digging around for what felt like ages trying to find a way to scrape the content of previous revisions of Wikipedia articles, I ended up building my own program to complete the task, using several other Wikipedia parsers to help reach that end. <a href="https://pypi.org/project/mwclient/">mwClient</a> allows simple scraping of the metadata of revisions, and the content of revisions given an revision ID. Put those two together and it’s possible to compile the list of revision IDs (and the metadata for those revisions) and get back a usable piece of text. Unfortunately, that text comes back as raw HTML—which means it needs to be parsed into plain text. Once that’s done, it’s returned and collected into an object.</p>

<p>Collecting the ratings for each version is a similar task. The program scrapes the text of each revision to the talk page of the article (where quality markers are tagged by users), and once revisions are collected, uses the wonderfully named <a href="https://mwparserfromhell.readthedocs.io/en/latest/">mwparserfromhell</a> to parse out the quality tag from the templates on each version of the talk page. Since edits are tagged by time, it’s simple enough to relate the time of a quality tag changing to the time of an edit, and associate the quality tags from the talk pages to the edits on the main page.</p>

<p>Using the tool is really simple, as it has pretty much a single functionality: Getting an article and returning back its complete history. The data collected was used for my Wikipedia research work, but I also hope the tool can be used for other projects and other analyses. I feel like I’ve only touched the tip of the iceberg of what’s possible with this tool.</p>

<p>Here’s a simple example illustrating the functionality of <code class="highlighter-rouge">wikipedia-histories</code>, using the <a href="https://en.wikipedia.org/wiki/Golden_swallow">golden swallow Wikipedia article</a> as an example.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">wikipedia_histories</span>
  
  <span class="c1"># Generate a list of revisions for a specified page
</span>  <span class="o">&gt;&gt;&gt;</span> <span class="n">golden_swallow</span> <span class="o">=</span> <span class="n">wikipedia_histories</span><span class="o">.</span><span class="n">get_history</span><span class="p">(</span><span class="s">'Golden swallow'</span><span class="p">)</span>
  
  <span class="c1"># Show the revision IDs for every edit
</span>  <span class="o">&gt;&gt;&gt;</span> <span class="n">golden_swallow</span>
  <span class="c1"># [130805848, 162259515, 167233740, 195388442, ...
</span>  
  <span class="c1"># Show the user who made a specific edit
</span>  <span class="o">&gt;&gt;&gt;</span> <span class="n">golden_swallow</span><span class="p">[</span><span class="mi">16</span><span class="p">]</span><span class="o">.</span><span class="n">user</span>
  <span class="c1"># u'Snowmanradio'
</span>  
  <span class="c1"># Show the text of at the time of a specific edit
</span>  <span class="o">&gt;&gt;&gt;</span> <span class="n">golden_swallow</span><span class="p">[</span><span class="mi">16</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
  <span class="c1"># u'The Golden Swallow (Tachycineta euchrysea) is a swallow.  The Golden Swallow formerly'...
</span>  
  <span class="c1"># Get the article rating at the time of the edit
</span>  <span class="o">&gt;&gt;&gt;</span> <span class="n">ratings</span> <span class="o">=</span> <span class="p">[</span><span class="n">revision</span><span class="o">.</span><span class="n">rating</span> <span class="k">for</span> <span class="n">revision</span> <span class="ow">in</span> <span class="n">golden_swallow</span><span class="p">]</span>
  <span class="o">&gt;&gt;&gt;</span> <span class="n">ratings</span>
  <span class="c1"># ['NA', 'NA', 'NA', 'NA', 'stub', 'stub', ...
</span></code></pre></div></div>

</div>
  

  </body>

</html>
